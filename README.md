## Ex-4: Scenario-Based Report Development Utilizing Diverse Prompting Techniques

## Objective:
The goal of this experiment is to design and develop an AI-powered chatbot that can handle customer inquiries, provide support, and improve customer experience in a retail environment. Create prompts using various AI prompting techniques to guide your experiment, data collection, analysis, and report creation.

## Aim:
To evaluate how diverse AI prompting techniques can be applied to create an effective scenario-based customer service chatbot for a retail environment, and to compare the quality of responses generated through these different prompting methods.

## Algorithm:

Identify Use Case:
Customer support in retail.
Example scenarios: product inquiry, return/refund policy, order tracking, troubleshooting.

Define Prompting Techniques:

Zero-shot prompting

One-shot prompting

Few-shot prompting

Chain-of-thought prompting

Role-based prompting

Contextual prompting

Instruction-based prompting

Socratic prompting

Comparative prompting

Persona-driven prompting

Design Prompts for Each Technique:
Frame a set of queries a retail customer might ask.
Apply each prompting method to the same queries.

Execute Prompts in AI Systems:
Use AI tools like ChatGPT, Claude, Bard, etc., to test consistency.

Collect Outputs:
Document responses generated for each scenario and technique.

Analyze Responses:
Compare clarity, accuracy, empathy, personalization, and effectiveness.

Document Results:
Report findings in detailed format with comparisons.

Conclude:
Summarize which prompting methods deliver the best customer experience.

## Prompts, Outputs, and Results:
# Scenario 1: Product Inquiry

Customer Question: “Do you have Nike running shoes in size 9?”

## (a) Zero-shot Prompting

Prompt: “Answer the customer’s query about product availability.”

Output: “We have Nike running shoes available in various sizes. For size 9, availability depends on current stock. Please check our online catalog or provide your location so I can confirm.”

Result: Response is generic but functional; lacks personalization and real-time stock check.

### (b) One-shot Prompting

Prompt: “Example: If a customer asks about iPhone 14 availability, say: ‘Yes, we have it in stock. Would you like delivery or in-store pickup?’ Now, answer this: Do you have Nike running shoes in size 9?”

Output: “Yes, we have Nike running shoes in size 9 available. Would you prefer home delivery or to pick them up in-store?”

Result: Clear and customer-friendly, but assumes stock availability.

### (c) Few-shot Prompting

# Prompt:
Q: “Do you have Samsung Galaxy S23 in stock?”
A: “Yes, we have it available. Would you like to order now?”
Q: “Can I buy Levi’s jeans in size 32?”
A: “Yes, Levi’s jeans in size 32 are available. Do you prefer pickup or delivery?”
Q: “Do you have Nike running shoes in size 9?”

Output: “Yes, Nike running shoes in size 9 are available. Would you like me to add them to your cart?”

Result: Polished, conversational, and sales-driven response.

### (d) Role-based Prompting

Prompt: “You are a friendly retail assistant. Answer the customer politely and helpfully: Do you have Nike running shoes in size 9?”

Output: “Of course! Let me check that for you. Yes, we have Nike running shoes in size 9. Would you like me to show you the available colors?”

Result: Engaging and personalized; makes customer feel valued.

### Result:

From this experiment, we can see that different prompting techniques create significant variations in chatbot performance:

Zero-shot prompting → Functional but generic, often lacking depth.

One-shot & few-shot prompting → Improved natural, polished, and sales-driven responses.

Role-based & persona-driven prompting → Added empathy and friendliness, improving customer satisfaction.

Chain-of-thought prompting → Best for structured troubleshooting.

Instruction-based prompting → Ideal for concise policies.

Socratic prompting → Useful for guiding but less direct.

### Conclusion:

The best-performing chatbot for a retail environment would combine:

Few-shot prompting (for accuracy & contextual responses)

Role-based prompting (for empathy & personalization)

### RESULT:
Different prompting techniques affect chatbot performance. Combining Few-shot, Role-based, and Chain-of-thought prompting gives the most effective and customer-friendly responses.

Chain-of-thought prompting (for troubleshooting & step-by-step guidance)

Together, these techniques ensure the chatbot is helpful, human-like, and reliable, ultimately enhancing the overall customer experience.
